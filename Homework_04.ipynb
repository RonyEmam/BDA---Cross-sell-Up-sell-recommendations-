{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cedtXySEYb28"
   },
   "source": [
    "<div class=\"alert alert-block alert-info\"><b></b>\n",
    "<h1><center> <font color='black'> Homework 04  </font></center></h1>\n",
    "<h2><center> <font color='black'> Cross-Selling/ Up-selling & Recommendation System</font></center></h2>   \n",
    "<h2><center> <font color='black'> MTAT.03.319 - Business Data Analytics</font></center></h2>\n",
    "<h2><center> <font color='black'> University of Tartu - Spring 2021</font></center></h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-pvZUeIYb3G"
   },
   "source": [
    "# Homework instructions\n",
    "\n",
    "- Please provide the names and student IDs of the team-members (Maximum 2 person) in the field \"Team mates\" below. If you are not working in a team please insert only your name and student ID. \n",
    "\n",
    "- The accepted submission formats are Colab links or .ipynb files. If you are submitting Colab links please make sure that the privacy settings for the file is public so we can access your code. \n",
    "\n",
    "- The submission will automatically close on <font color='red'>**18 April at 23:59**</font>, so please make sure to submit before the deadline. \n",
    "\n",
    "- ONLY one of the teammates should submit the homework. We will grade the homework and the marks and feedback is applied for both the team members. So please communicate with your team member about marks and feedback if you are submit the homework.\n",
    "\n",
    "- If a question is not clear, please ask us in Moodle ONLY. \n",
    "\n",
    "- After you have finished solving the Homework, please restart the Kernel and run all the cells to check if there is any persisting issues. \n",
    "\n",
    "- Plagiarism is <font color='red'>**PROHIBITED**</font>. Any form of plagiarism will be dealt according to the university policy (https://www.ut.ee/en/current-students/academic-fraud).\n",
    "\n",
    "- Please <font color='red'>do not change</font> the template of this notebook file. You can download the .ipynb file and work on that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OWlFadiYb3I"
   },
   "source": [
    "**<h2><font color='red'>Team mates:</font></h2>**\n",
    "\n",
    "\n",
    "**<font color='red'>Name: Mohga Emam</font>&emsp;   <font color='red'>Student ID: C09505</font>**\n",
    "\n",
    "\n",
    "**<font color='red'>Name: Rewan Emam</font>&emsp;   <font color='red'>Student ID: C07851</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pL7tscuuAtWp"
   },
   "source": [
    "### The homework is divided into four sections and the points are distributed as below:\n",
    "<pre>\n",
    "- Market Basket Analysis            -> 2.0 points\n",
    "- Collaborative Filtering           -> 3.5 points\n",
    "- Recommender Systems Evaluation    -> 1.0 points\n",
    "- Neural Network                    -> 2.5 points\n",
    "_________________________________________________\n",
    "Total                               -> 9.0 points\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boFT1CkoYb3K"
   },
   "source": [
    "# 1.  Market Basket Analysis (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a3hBebgbYb3M"
   },
   "source": [
    "**1.1 Consider the following businesses and think about one case of cross selling and one case of up selling techniques they could use. This question is not restricted to only traditional, standard examples.(1 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDlcP-zGGscx"
   },
   "source": [
    "### <font color='red'> **I apologize for the inconvience but no matter what I do the text icon shows part of what I am writing so kindly click on the points [a, b, c, d] as you are editing them to see my full answer**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HxMUA01DYb3P"
   },
   "source": [
    "a. An OnlineTravel Agency like Booking.com or AirBnB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RODzp7BPYb3T"
   },
   "source": [
    "<font color='red'> **Cross selling: I booked a room in a certain hotel and it offered collection of effors for Taxi booking from the airport with good prices.**</font> \n",
    "\n",
    "<font color='red'> **Up selling: I booked a room in a certain hotel and it shows that it's not refundable but if I instead pick another room with more features the food coupon will increase and there's no payment needed, I can pay while checking in. and free cancelation before 2 days of the reservation. The difference between the two of them are less than $70.**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qbw_w9p1Yb3U"
   },
   "source": [
    "b. A software company which produces products related to cyber security like Norton, Kaspersky, Avast and similar ones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0SyXnB6Yb3W"
   },
   "source": [
    "<font color='red'> **Cross selling: I wanted to purchase the basic package [Norton Anti-Virus] with $34.99, it shows me 2 other great packages [ Norton computer tune up] which helps my computer run like new again for $49.99 and the other one is [Norton family], which guarantee safe, secure connection for kids for $49.99.**</font> \n",
    "\n",
    "<font color='red'> **Up selling:[text is hidden kindly open the text] I wanted to purchase Norton package for $37.99 with %45 But the site recommended to instead purchase Norton 360 Premium Plus with 95% discount with 6 more features and only for $59.99**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EUCv8TtYb3X"
   },
   "source": [
    "c. A company that sells cell phones\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NFHO-dI6Yb3Y"
   },
   "source": [
    "<font color='red'> **Cross selling: I added to the cart Iphone 11, and then down below the wesite shows adapters & headsets for Ipone 11 with vival colors**</font> \n",
    "\n",
    "<font color='red'> **Up selling: I clicked on the headsets icon to pick one with my Iphone 11, and I have selected one with the price of EarPods with 3.5 mm Headphone Plug for $19. The |site| showed| me |that |the |headset [Beats flex all day wireless] for |only $27.99**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wnH4-lrYb3a"
   },
   "source": [
    "d. A supermarket like Konsum, Rimi, Maxima etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4CNtNYBYb3b"
   },
   "source": [
    "<font color='red'> **Cross selling: I added to the cart chicken and it shows spicies of chicken for a great teste, 20% discount on the Rice [1 Kg]**</font>\n",
    "\n",
    "<font color='red'> **Up selling: I added to the cart Tissue paper [8 pieces] to buy it for price 2.53 Euros, instead I found down below that if I took from different company Tissue paper [16 pieces] it would be with the price of 4.20 Euros.**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLp7o0cdYb3c"
   },
   "source": [
    "**1.2 Let's suppose that our client is a retail company that has an online shop. They gave us a dataset about online sales of their products. The client wants to know which product bundles to promote. Find 5 association rules with the highest lift.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7HLlQ30Yb3e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/RewanEmam/Customer-Segmentation-files/main/OnlineRetailPurchase.csv', header=0, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "VWBRFwuUYb3l",
    "outputId": "03b8e1f1-99ea-43f5-a1ad-e56019281552"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode  ... CustomerID         Country\n",
       "0    536365    85123A  ...    17850.0  United Kingdom\n",
       "1    536365     71053  ...    17850.0  United Kingdom\n",
       "2    536365    84406B  ...    17850.0  United Kingdom\n",
       "3    536365    84029G  ...    17850.0  United Kingdom\n",
       "4    536365    84029E  ...    17850.0  United Kingdom\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kcjIimkHYb35"
   },
   "source": [
    "**1.3 Use describe function from pandas to get statistical information about the values in the dataframe.(0.2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RakInjZBY4Wu"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5a0X9dtYb4K"
   },
   "source": [
    "**1.4 Create a dataframe name as \"Basket\", where each row has an distintive value of InvoiceNo and each column has a distinctive Description. The cells in the table contain the count of each item (Description) mentioned in one invoice. For example basket.loc['536365','WHITE HANGING HEART T-LIGHT HOLDER'] has a value of 1 because the product with WHITE HANGING HEART T-LIGHT HOLDER was entered  only once in the invoice 536365. (0.2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "id": "D4lUPlKAYb4L"
   },
   "outputs": [],
   "source": [
    "Basket = df[['InvoiceNo', 'Description']]\n",
    "basket = Basket.drop_duplicates(subset = ['InvoiceNo', 'Description'],keep= 'last').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 526
    },
    "id": "IyRIzurWPrMl",
    "outputId": "22f7289f-acaa-4d76-cb00-9175d3f499c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4 PURPLE FLOCK DINNER CANDLES</th>\n",
       "      <th>OVAL WALL MIRROR DIAMANTE</th>\n",
       "      <th>SET 2 TEA TOWELS I LOVE LONDON</th>\n",
       "      <th>10 COLOUR SPACEBOY PEN</th>\n",
       "      <th>12 COLOURED PARTY BALLOONS</th>\n",
       "      <th>12 DAISY PEGS IN WOOD BOX</th>\n",
       "      <th>12 IVORY ROSE PEG PLACE SETTINGS</th>\n",
       "      <th>12 MESSAGE CARDS WITH ENVELOPES</th>\n",
       "      <th>12 PENCIL SMALL TUBE WOODLAND</th>\n",
       "      <th>12 PENCILS SMALL TUBE RED RETROSPOT</th>\n",
       "      <th>12 PENCILS SMALL TUBE SKULL</th>\n",
       "      <th>12 PENCILS TALL TUBE POSY</th>\n",
       "      <th>12 PENCILS TALL TUBE RED RETROSPOT</th>\n",
       "      <th>12 PENCILS TALL TUBE SKULLS</th>\n",
       "      <th>12 PENCILS TALL TUBE WOODLAND</th>\n",
       "      <th>12 PINK ROSE PEG PLACE SETTINGS</th>\n",
       "      <th>12 RED ROSE PEG PLACE SETTINGS</th>\n",
       "      <th>15CM CHRISTMAS GLASS BALL 20 LIGHTS</th>\n",
       "      <th>20 DOLLY PEGS RETROSPOT</th>\n",
       "      <th>200 BENDY SKULL STRAWS</th>\n",
       "      <th>200 RED + WHITE BENDY STRAWS</th>\n",
       "      <th>3 GARDENIA MORRIS BOXED CANDLES</th>\n",
       "      <th>3 HEARTS HANGING DECORATION RUSTIC</th>\n",
       "      <th>3 HOOK HANGER MAGIC GARDEN</th>\n",
       "      <th>3 HOOK PHOTO SHELF ANTIQUE WHITE</th>\n",
       "      <th>3 PIECE SPACEBOY COOKIE CUTTER SET</th>\n",
       "      <th>3 ROSE MORRIS BOXED CANDLES</th>\n",
       "      <th>3 STRIPEY MICE FELTCRAFT</th>\n",
       "      <th>3 TIER CAKE TIN GREEN AND CREAM</th>\n",
       "      <th>3 TIER CAKE TIN RED AND CREAM</th>\n",
       "      <th>3 TRADITIONAL COOKIE CUTTERS  SET</th>\n",
       "      <th>3 TRADITIONAl BISCUIT CUTTERS  SET</th>\n",
       "      <th>3 WHITE CHOC MORRIS BOXED CANDLES</th>\n",
       "      <th>36 DOILIES DOLLY GIRL</th>\n",
       "      <th>36 FOIL HEART CAKE CASES</th>\n",
       "      <th>36 FOIL STAR CAKE CASES</th>\n",
       "      <th>36 PENCILS TUBE POSY</th>\n",
       "      <th>36 PENCILS TUBE RED RETROSPOT</th>\n",
       "      <th>36 PENCILS TUBE SKULLS</th>\n",
       "      <th>36 PENCILS TUBE WOODLAND</th>\n",
       "      <th>...</th>\n",
       "      <th>WOODEN ROUNDERS GARDEN SET</th>\n",
       "      <th>WOODEN SCHOOL COLOURING SET</th>\n",
       "      <th>WOODEN STAR CHRISTMAS SCANDINAVIAN</th>\n",
       "      <th>WOODEN TREE CHRISTMAS SCANDINAVIAN</th>\n",
       "      <th>WOODEN UNION JACK BUNTING</th>\n",
       "      <th>WOODLAND  HEIGHT CHART STICKERS</th>\n",
       "      <th>WOODLAND CHARLOTTE BAG</th>\n",
       "      <th>WOODLAND DESIGN  COTTON TOTE BAG</th>\n",
       "      <th>WOODLAND PARTY BAG + STICKER SET</th>\n",
       "      <th>WOODLAND STORAGE BOX LARGE</th>\n",
       "      <th>WOODLAND STORAGE BOX SMALL</th>\n",
       "      <th>WORLD WAR 2 GLIDERS ASSTD DESIGNS</th>\n",
       "      <th>WOVEN BERRIES CUSHION COVER</th>\n",
       "      <th>WRAP  PINK FLOCK</th>\n",
       "      <th>WRAP CHRISTMAS SCREEN PRINT</th>\n",
       "      <th>WRAP CHRISTMAS VILLAGE</th>\n",
       "      <th>WRAP COWBOYS</th>\n",
       "      <th>WRAP ENGLISH ROSE</th>\n",
       "      <th>WRAP GREEN PEARS</th>\n",
       "      <th>WRAP PINK FAIRY CAKES</th>\n",
       "      <th>WRAP RED APPLES</th>\n",
       "      <th>WRAP SUKI AND FRIENDS</th>\n",
       "      <th>WRAP, BILLBOARD FONTS DESIGN</th>\n",
       "      <th>YELLOW BREAKFAST CUP AND SAUCER</th>\n",
       "      <th>YELLOW COAT RACK PARIS FASHION</th>\n",
       "      <th>YELLOW FLOWERS FELT HANDBAG KIT</th>\n",
       "      <th>YELLOW GIANT GARDEN THERMOMETER</th>\n",
       "      <th>YELLOW METAL CHICKEN HEART</th>\n",
       "      <th>YELLOW SHARK HELICOPTER</th>\n",
       "      <th>YELLOW/PINK CERAMIC CANDLE HOLDER</th>\n",
       "      <th>YELLOW/PINK FLOWER DESIGN BIG MUG</th>\n",
       "      <th>YOU'RE CONFUSING ME METAL SIGN</th>\n",
       "      <th>YULETIDE IMAGES GIFT WRAP SET</th>\n",
       "      <th>YULETIDE IMAGES S/6 PAPER BOXES</th>\n",
       "      <th>ZINC FINISH 15CM PLANTER POTS</th>\n",
       "      <th>ZINC FOLKART SLEIGH BELLS</th>\n",
       "      <th>ZINC HEART LATTICE T-LIGHT HOLDER</th>\n",
       "      <th>ZINC METAL HEART DECORATION</th>\n",
       "      <th>ZINC WILLIE WINKIE  CANDLE STICK</th>\n",
       "      <th>amazon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9643</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9644</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9645</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9646</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9648 rows × 1981 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       4 PURPLE FLOCK DINNER CANDLES  ...  amazon\n",
       "0                                  0  ...       0\n",
       "1                                  0  ...       0\n",
       "2                                  0  ...       0\n",
       "3                                  0  ...       0\n",
       "4                                  0  ...       0\n",
       "...                              ...  ...     ...\n",
       "9643                               0  ...       0\n",
       "9644                               0  ...       0\n",
       "9645                               0  ...       0\n",
       "9646                               0  ...       0\n",
       "9647                               0  ...       0\n",
       "\n",
       "[9648 rows x 1981 columns]"
      ]
     },
     "execution_count": 329,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket = pd.get_dummies(basket['Description'])\n",
    "basket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rwKSVg3Yb4d"
   },
   "source": [
    "**1.5 Some products are mentioned more than once in one invoice. You can check the maximum number for each column to verify. Modify your dataframe such that every cell which has a value higher than one will be replaced with 1. If the cell has the value 0 it will remain the same. (0.2 points)** <br>\n",
    "NB: If your implementation in 1.4 already takes care of this, please skip the question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BO17Wy1Yb4e"
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfWgocGTYb4k"
   },
   "source": [
    "**1.5 We do not need to spend time on calculating the association rules by ourselves as there already exists a package for python to do so, called mlxtend. We are going to use the mlxtend package to find frequent items bought together and then create some rules on what to recomend to a user based on what he/she/they have bought. We have given you the first part of the code which calculates the frequent items bought together. (0.2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCw4ii7tYb4l"
   },
   "outputs": [],
   "source": [
    "#!pip install mlxtend\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import mlxtend as ml\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQBjILk5Yb4p"
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcF5RyYRYb4y"
   },
   "source": [
    "**Please read the documentation of the associaton rules function in mlextend [here](http://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/) and complete the code so we get the 5 rules with the highest lift. Print those rules. For example if user bought product basket A then  the algorithm recommends product basket B. (0.2 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLpV1FkKYb41"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rules = ... #TODO\n",
    "\n",
    "\n",
    "\n",
    "for index, row in (rules.iloc[:5]).iterrows():\n",
    "    print(\"If the customer buys \" + str(row['antecedents']))\n",
    "    print(\"\")\n",
    "    print(\"The recommender recommends \"+str(row['consequents']))\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRqo0ek4Yb47"
   },
   "source": [
    "# 2. Collaborative filtering (3.5 points )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U1OvsCJYb48"
   },
   "source": [
    "We are going to use Books.csv dataset which contains  ratings from Amazon website and the data has the following features:\n",
    "\n",
    "UserID: The ID of the users who read the books\n",
    "\n",
    "BookTitle: The title of the book\n",
    "\n",
    "Book-Rating: A rating given to the book in a scale from 0 to 10\n",
    "\n",
    "Below we are going to perform the same steps we did with movies dataset in the practice session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-wOm7yLYb49"
   },
   "source": [
    "**2.0 Load the dataset and take a look at the books titles. And pick a favorite book (any book).(0.1 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "id": "Z_2CgjU6Yb4-",
    "outputId": "f7d694ea-a181-41ce-9b13-36bb4e395c1f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6181</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UserID  Book-Rating             BookTitle\n",
       "0    6181            0  Flesh Tones: A Novel\n",
       "1      62            5  Flesh Tones: A Novel\n",
       "2     163            0  Flesh Tones: A Novel\n",
       "3     212            5  Flesh Tones: A Novel\n",
       "4     250            9  Flesh Tones: A Novel"
      ]
     },
     "execution_count": 277,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_book = pd.read_csv('https://raw.githubusercontent.com/RewanEmam/Customer-Segmentation-files/main/Books.csv', header=0, sep = ',', usecols=['UserID', 'Book-Rating', 'BookTitle'])\n",
    "df_book.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "IBmxbi5zS2j_",
    "outputId": "d75fd654-f89b-470e-bb76-9c1e6552412a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>BookTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6181</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>212</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>9</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>3663</td>\n",
       "      <td>0</td>\n",
       "      <td>Wild Animus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>3665</td>\n",
       "      <td>0</td>\n",
       "      <td>Wild Animus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>3666</td>\n",
       "      <td>3</td>\n",
       "      <td>Wild Animus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3668</td>\n",
       "      <td>9</td>\n",
       "      <td>Wild Animus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>3670</td>\n",
       "      <td>0</td>\n",
       "      <td>Wild Animus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9998 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserID  Book-Rating             BookTitle\n",
       "0       6181            0  Flesh Tones: A Novel\n",
       "1         62            5  Flesh Tones: A Novel\n",
       "2        163            0  Flesh Tones: A Novel\n",
       "3        212            5  Flesh Tones: A Novel\n",
       "4        250            9  Flesh Tones: A Novel\n",
       "...      ...          ...                   ...\n",
       "9993    3663            0           Wild Animus\n",
       "9994    3665            0           Wild Animus\n",
       "9995    3666            3           Wild Animus\n",
       "9996    3668            9           Wild Animus\n",
       "9997    3670            0           Wild Animus\n",
       "\n",
       "[9998 rows x 3 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfBook = df_book.drop_duplicates(subset = ['BookTitle', 'UserID'],keep= 'last').reset_index(drop = True)\n",
    "dfBook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_f2ywpLYb5J"
   },
   "source": [
    "**2.1 You have to apply KNN algorithm for collaborative filtering. As KNN algorithm does not accept strings, use a Label Encoder for BookTitle column.After that reshape the books matrix so that every column will be a UserID and every row a BookTitle. (0.45 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "-Gs_CAGKYb5K",
    "outputId": "cf29f200-b9aa-46d8-d0f2-928a16497bf3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>UserID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>6252</th>\n",
       "      <th>6253</th>\n",
       "      <th>6254</th>\n",
       "      <th>6255</th>\n",
       "      <th>6256</th>\n",
       "      <th>6257</th>\n",
       "      <th>6258</th>\n",
       "      <th>6259</th>\n",
       "      <th>6260</th>\n",
       "      <th>6261</th>\n",
       "      <th>6262</th>\n",
       "      <th>6263</th>\n",
       "      <th>6264</th>\n",
       "      <th>6265</th>\n",
       "      <th>6266</th>\n",
       "      <th>6267</th>\n",
       "      <th>6268</th>\n",
       "      <th>6269</th>\n",
       "      <th>6270</th>\n",
       "      <th>6271</th>\n",
       "      <th>6272</th>\n",
       "      <th>6273</th>\n",
       "      <th>6274</th>\n",
       "      <th>6275</th>\n",
       "      <th>6276</th>\n",
       "      <th>6277</th>\n",
       "      <th>6278</th>\n",
       "      <th>6279</th>\n",
       "      <th>6280</th>\n",
       "      <th>6281</th>\n",
       "      <th>6282</th>\n",
       "      <th>6283</th>\n",
       "      <th>6284</th>\n",
       "      <th>6285</th>\n",
       "      <th>6286</th>\n",
       "      <th>6287</th>\n",
       "      <th>6288</th>\n",
       "      <th>6289</th>\n",
       "      <th>6290</th>\n",
       "      <th>6291</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookTitle</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>007 El Mundo Nunca Es Suficiente</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4000 Vornamen aus aller Welt. Von Alexander bis Zoe.</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Kid's Guide to How to Save the Planet (Camelot world)</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Kiss of Shadows (Meredith Gentry Novels (Paperback))</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A Painted House</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6292 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "UserID                                              0     1     ...  6290  6291\n",
       "BookTitle                                                       ...            \n",
       "007 El Mundo Nunca Es Suficiente                     0.0   0.0  ...   0.0   0.0\n",
       "4000 Vornamen aus aller Welt. Von Alexander bis...   0.0   0.0  ...   0.0   0.0\n",
       "A Kid's Guide to How to Save the Planet (Camelo...   0.0   0.0  ...   0.0   0.0\n",
       "A Kiss of Shadows (Meredith Gentry Novels (Pape...   0.0   0.0  ...   0.0   0.0\n",
       "A Painted House                                      0.0   0.0  ...   0.0   0.0\n",
       "\n",
       "[5 rows x 6292 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# label encounter\n",
    "label = preprocessing.LabelEncoder()\n",
    "dfBook['BookName'] = labelencoder.fit_transform(dfBook['BookTitle'])\n",
    "\n",
    "# every column is userid\n",
    "df_boo = dfBook.pivot(index = 'BookTitle', columns='UserID', values='Book-Rating').fillna(0)\n",
    "df_boo.index.names = ['BookTitle']\n",
    "df_boo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4RwLx90KYb5R"
   },
   "source": [
    "**2.2 Build a sparse matrix for books data and show it. (0.45 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uwVtesasYb5U",
    "outputId": "731e9ac4-9c97-4ec7-bd25-0dc17c1eaa00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix:\n",
      "  (1, 6228)\t5.0\n",
      "  (2, 365)\t7.0\n",
      "  (2, 5110)\t9.0\n",
      "  (2, 5226)\t10.0\n",
      "  (2, 6209)\t10.0\n",
      "  (3, 91)\t7.0\n",
      "  (3, 135)\t8.0\n",
      "  (3, 139)\t10.0\n",
      "  (3, 258)\t9.0\n",
      "  (3, 429)\t6.0\n",
      "  (3, 760)\t5.0\n",
      "  (3, 821)\t6.0\n",
      "  (3, 869)\t9.0\n",
      "  (3, 984)\t10.0\n",
      "  (3, 1328)\t5.0\n",
      "  (3, 1425)\t10.0\n",
      "  (3, 1781)\t2.0\n",
      "  (3, 1815)\t9.0\n",
      "  (3, 1820)\t9.0\n",
      "  (3, 1951)\t8.0\n",
      "  (3, 2360)\t8.0\n",
      "  (3, 2384)\t8.0\n",
      "  (3, 2449)\t9.0\n",
      "  (3, 2468)\t7.0\n",
      "  (3, 2956)\t5.0\n",
      "  :\t:\n",
      "  (333, 3411)\t4.0\n",
      "  (333, 3416)\t1.0\n",
      "  (333, 3433)\t8.0\n",
      "  (333, 3445)\t5.0\n",
      "  (333, 3450)\t2.0\n",
      "  (333, 3456)\t4.0\n",
      "  (333, 3461)\t8.0\n",
      "  (333, 3491)\t2.0\n",
      "  (333, 3497)\t1.0\n",
      "  (333, 3501)\t4.0\n",
      "  (333, 3518)\t8.0\n",
      "  (333, 3519)\t3.0\n",
      "  (333, 3527)\t7.0\n",
      "  (333, 3543)\t7.0\n",
      "  (333, 3546)\t9.0\n",
      "  (333, 3547)\t7.0\n",
      "  (333, 3573)\t5.0\n",
      "  (333, 3575)\t1.0\n",
      "  (333, 3581)\t7.0\n",
      "  (333, 3597)\t3.0\n",
      "  (333, 3602)\t6.0\n",
      "  (333, 3666)\t3.0\n",
      "  (333, 3668)\t9.0\n",
      "  (333, 6250)\t2.0\n",
      "  (333, 6277)\t9.0\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "df_boo_sparse = csr_matrix(df_boo.values)\n",
    "print(f\"Sparse matrix:\\n{df_boo_sparse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_qDjXo8fezvk",
    "outputId": "51ec5b57-7054-47fb-eafa-fb0ae0cc252c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'007 El Mundo Nunca Es Suficiente': 0,\n",
       " '4000 Vornamen aus aller Welt. Von Alexander bis Zoe.': 1,\n",
       " \"A Kid's Guide to How to Save the Planet (Camelot world)\": 6,\n",
       " 'A Kiss of Shadows (Meredith Gentry Novels (Paperback))': 81,\n",
       " 'A Painted House': 246,\n",
       " 'A String in the Harp': 251,\n",
       " 'A Wrinkle In Time': 395,\n",
       " 'Adressat unbekannt.': 404,\n",
       " 'Advanced Photography, Sixth Edition': 406,\n",
       " 'Alaska': 476,\n",
       " \"Alice's Adventures in Wonderland and Through the Looking Glass\": 503,\n",
       " 'Alone with the Dead (Joe Keough Mysteries (Paperback))': 513,\n",
       " 'Along Came a Spider (Alex Cross Novels)': 784,\n",
       " 'Alte Freunde, neue Feinde. Ein Fall f�?¼r Bernhard Gunther.': 786,\n",
       " 'Anna Karenina': 788,\n",
       " 'Apricots on the Nile: A Memoir with Recipes': 792,\n",
       " 'Artemis Fowl (Artemis Fowl, Book 1)': 936,\n",
       " 'Artemis Fowl.': 958,\n",
       " 'Asche zu Asche.': 972,\n",
       " 'At the Edge': 978,\n",
       " 'Attack Of The Deranged Mutant Killer Snow Goons': 1012,\n",
       " 'Auf Ehre und Gewissen. Roman.': 1024,\n",
       " 'Auf der Suche nach dem verlorenen Gl�?¼ck.': 1025,\n",
       " 'Auf d�?¼nnem Eis.': 1027,\n",
       " \"BD Pirate : Cupidon, tome 2 : Philtre d'amour\": 1029,\n",
       " 'BD Pirate : Cupidon, tome 3 : Baiser de feu': 1031,\n",
       " \"Back When We Were Grownups : A Novel (Ballantine Reader's Circle)\": 1148,\n",
       " 'Battle Angel Alita - Fallen Angel (Battle Angel Alita , No.8)': 1149,\n",
       " 'Beim Naechsten Mann Wird Alles (Frau in Der Gesellschaft)': 1169,\n",
       " 'Benedict Canyon': 1171,\n",
       " 'Besiegt vom Sturm der Leidenschaft.': 1172,\n",
       " \"Big Girls Don't Cry\": 1175,\n",
       " 'Birdsong: A Novel of Love and War': 1219,\n",
       " 'Black Box (Vintage International)': 1220,\n",
       " 'Blackwood Farm (Rice, Anne, Vampire Chronicles.)': 1263,\n",
       " 'Blooded (Buffy the Vampire Slayer, Book 5)': 1278,\n",
       " 'Bloomability': 1284,\n",
       " \"Bridget Jones's Diary\": 1401,\n",
       " \"Bridget Jones's Diary: Music from the Motion Picture\": 1407,\n",
       " 'Bridget Jones:Sobreviviré': 1410,\n",
       " 'Briefe der Liebe.': 1412,\n",
       " 'Buzon De Tiempo': 1414,\n",
       " 'CLOUT': 1415,\n",
       " 'Calvin and Hobbes': 1454,\n",
       " 'Canone inverso: Romanzo (Scrittori italiani)': 1455,\n",
       " 'Change Your Job, Change Your Life: High Impact Strategies for Finding Great Jobs in the Decade Ahead (Change Your Job Change Your Life, 7th ed)': 1456,\n",
       " \"Childhood's End\": 1459,\n",
       " 'Cinco Semanas En Globo (Espasa Bolsillo)': 1460,\n",
       " 'Close to the Bone': 1473,\n",
       " 'Close to the Knives': 1474,\n",
       " 'Codice: Racconto (Varianti)': 1475,\n",
       " \"Comp Murphy's Law\": 1476,\n",
       " \"Contes De Ma Mere L'Oye\": 1479,\n",
       " 'Crows': 1482,\n",
       " 'Cuentos Inconclusos': 1484,\n",
       " 'C�?¤sar und Kleopatra. Die letzten Tage der R�?¶mischen Republik.': 1485,\n",
       " 'Dark Angel (Casteel)': 1508,\n",
       " 'Dark Paradise': 1636,\n",
       " 'Das Haus auf den Klippen.': 1637,\n",
       " 'Das Lacheln der Fortuna: Historischer Roman': 1649,\n",
       " 'Das Schwarze Auge. Aus dunkler Tiefe.': 1651,\n",
       " 'Das Superwieb': 1681,\n",
       " 'Das bizarre Sexualleben der Tiere. Ein popul�?¤res Lexikon von Aal bis Zebra.': 1682,\n",
       " 'Das geheime ABC der Toten.': 1684,\n",
       " 'Dear Children of the Earth: A Letter from Home': 1685,\n",
       " 'Demon in My View (Laurel-Leaf Books)': 1688,\n",
       " 'Denn keiner ist ohne Schuld.': 1697,\n",
       " 'Denn sie betr�?¼gt man nicht.': 1709,\n",
       " 'Der Bronzeh�?¤ndler.': 1710,\n",
       " 'Der Englishche Patient': 1720,\n",
       " 'Der Geschichtenverk�?¤ufer.': 1726,\n",
       " 'Der Goldene Kompass / The Golden Compass': 1730,\n",
       " 'Der Herr der Ringe. Anh�?¤nge und Register.': 1731,\n",
       " 'Der Kleine Hobbit': 1746,\n",
       " 'Der Regenmacher.': 1761,\n",
       " 'Der Spion und die Zauberin.': 1763,\n",
       " 'Der Stein der Kelten.': 1768,\n",
       " 'Der Sterne Tennisb�?¤lle.': 1775,\n",
       " 'Der Tag X.': 1777,\n",
       " 'Der Unsichtbare. ( Ab 13 J.).': 1778,\n",
       " 'Der Unterh�?¤ndler.': 1780,\n",
       " 'Des bateaux dans la nuit': 1784,\n",
       " 'Desert Flower : The Extraordinary Journey Of A Desert Nomad': 1802,\n",
       " 'Deux Grands Ducs Dans La Famille (Collection Des Deux Solitudes: Jeunesse)': 1803,\n",
       " 'Die Benachteiligung erfolgt durch die Post. Stilbl�?¼ten aus Inseraten und Pressenotizen.': 1804,\n",
       " 'Die Chirurgin.': 1805,\n",
       " 'Die Dinge des Lebens.': 1807,\n",
       " 'Die Firma. Roman.': 1823,\n",
       " 'Die Gefahrten I': 1831,\n",
       " 'Die Hirnk�?¶nigin.': 1847,\n",
       " 'Die H�?¤upter meiner Lieben.': 1869,\n",
       " 'Die Jury. Roman.': 1890,\n",
       " 'Die Krone der Welt.': 1893,\n",
       " 'Die Kunst des Verschwindens.': 1895,\n",
       " 'Die M�?¤dchen mit den dunklen Augen.': 1897,\n",
       " 'Die Scheibenwelt. Zwei Romane in einem Band. Das Licht der Phantasie / Das Erbe des Zauberers.': 1900,\n",
       " 'Die St�?¶renfrieds. Geschichten von Leo und Paulina.': 1904,\n",
       " 'Die Teufelin. Roman.': 1905,\n",
       " 'Die Tochter der W�?¤lder.': 1907,\n",
       " 'Die Weiss Lowin / Contemporary German Lit': 1930,\n",
       " 'Die Welle': 1936,\n",
       " 'Die Wiederkehr Des Konigs III': 1940,\n",
       " 'Die Wolfsfrau. Die Kraft der weiblichen Urinstinkte.': 1944,\n",
       " 'Die Zauberfrau.': 1959,\n",
       " 'Die Zauberin von Ruwenda.': 1970,\n",
       " 'Die Zwei Turme II': 1975,\n",
       " 'Die rote Antilope.': 1977,\n",
       " 'Die siebte Gei�?�?el.': 1984,\n",
       " 'Die zweite Haut.': 1989,\n",
       " 'Durch Teebaum�?¶l gesund und sch�?¶n.': 1990,\n",
       " 'East, West': 1993,\n",
       " 'Ein Fall f�?¼r Kay Scarpetta / Ein Mord f�?¼r Kay Scarpetta. Zwei Romane in einem Band.': 1996,\n",
       " 'Ein Liebhaber zuviel ist noch zu wenig.': 2000,\n",
       " 'Ein Mann f�?¼r jede Tonart. Roman. ( Die Frau in der Gesellschaft).': 2020,\n",
       " 'El Diaro De Bridget Jones': 2027,\n",
       " 'El Elogio de La Sombra': 2031,\n",
       " 'El Perfume: Historia De UN Asesino/Perfume : The Story of a Murderer': 2038,\n",
       " 'El Principito': 2046,\n",
       " \"Ender's Game (Ender Wiggins Saga (Paperback))\": 2066,\n",
       " 'Endlich Nichtraucher.': 2077,\n",
       " 'Escarabajos Vuelan Al Atardecer, Los': 2080,\n",
       " 'Estação Carandiru': 2082,\n",
       " 'False Memory': 2119,\n",
       " 'Field of Dishonor (Honor Harrington Series, Book 4)': 2128,\n",
       " 'Flesh Tones: A Novel': 2181,\n",
       " 'Flight of Eagles': 2184,\n",
       " 'Forbidden Forest: The Story of Little John and Robin Hood': 2187,\n",
       " 'Frankenstein (Dover Thrift Editions)': 2219,\n",
       " 'French Cuisine for All': 2220,\n",
       " 'Garzanti - Gli Elefanti: Altre Inquisizioni': 2223,\n",
       " 'Gates of Paradise (Casteel)': 2247,\n",
       " 'Gevatter Tod. Roman. ( Fantasy).': 2252,\n",
       " 'Girl Coming in for a Landing': 2253,\n",
       " 'Go Ask Alice (Avon/Flare Book)': 2292,\n",
       " 'God Game': 2293,\n",
       " \"Going Inside: A Couple's Journey of Renewal into the North\": 2294,\n",
       " 'Goldmann: Feuer in Berlin': 2296,\n",
       " 'Gratsch.': 2297,\n",
       " 'Great British Ghosts (Longman Structural Readers: Background)': 2298,\n",
       " 'Growing Wings': 2302,\n",
       " 'Harold and the Purple Crayon 50th Anniversary Edition (Purple Crayon Books)': 2314,\n",
       " 'Harry Potter Schoolbooks: Quidditch Through the Ages and Fantastic Beasts and Where to Find Them': 2327,\n",
       " 'Harry Potter Und Der Feuerkelch': 2338,\n",
       " 'Harry Potter and the Order of the Phoenix (Book 5)': 2643,\n",
       " 'Harry Potter and the Prisoner of Azkaban': 2645,\n",
       " \"Harry Potter and the Sorcerer's Stone Movie Poster Book\": 2650,\n",
       " 'Harry Potter und der Gefangene von Azkaban': 2662,\n",
       " 'Harry Potter und der Stein der Weisen': 2681,\n",
       " 'Harry Potter und die Kammer des Schreckens': 2695,\n",
       " 'Hasenherz. Roman.': 2700,\n",
       " 'Help!: Level 1': 2701,\n",
       " 'Henry der Held.': 2704,\n",
       " 'High Stakes': 2717,\n",
       " 'Hitlers Kinder.': 2718,\n",
       " 'Hoot (Newbery Honor Book)': 2733,\n",
       " 'House of the Sun (Shadowrun)': 2735,\n",
       " 'How Stella Got Her Groove Back': 2817,\n",
       " 'How To Win Friends And Influence People': 2864,\n",
       " 'How to Deal With Difficult People': 2865,\n",
       " 'How to Deal With Your Parents: When They Still Treat You Like a Child': 2868,\n",
       " 'Ice Blade: Snow Country (Ice Blade)': 2869,\n",
       " 'Ich liebe Dich!: Ein Eisenbahnroman mit 66 Intermezzos': 2870,\n",
       " 'Ich, Prinzessin aus dem Hause Al Saud. Ein Leben hinter tausend Schleiern.': 2876,\n",
       " 'Il birraio di Preston (La memoria)': 2882,\n",
       " 'Im Angesicht des Feindes.': 2891,\n",
       " 'Im Eishaus.': 2907,\n",
       " 'Im Fr�?¼hling singt zum letztenmal die Lerche.': 2908,\n",
       " 'Im Keller.': 2911,\n",
       " 'Im Netz der Spinnen. Videokill.': 2912,\n",
       " 'Im Schatten der Lilie. Die Erinnerungen der Eleonore von Aquitanien.': 2915,\n",
       " 'In Cold Blood (Vintage International)': 2963,\n",
       " 'Inspektor Jury bricht das Eis. Roman.': 2965,\n",
       " 'Inspektor Jury k�?¼�?�?t die Muse. Roman.': 2970,\n",
       " 'Invitacion a la Etica': 2972,\n",
       " 'Isabelle Eberhardt': 2973,\n",
       " \"Iznogoud, tome 2 : Les complots d'Iznogoud\": 2975,\n",
       " 'Jane Eyre (Dover Thrift Editions)': 2995,\n",
       " 'Jean-Edern Hallier': 2997,\n",
       " 'Journey Through Nature (Journey Through Series)': 2998,\n",
       " 'Kaltgestellt.': 3006,\n",
       " 'Katie.com': 3009,\n",
       " 'Keiner werfe den ersten Stein. Roman.': 3014,\n",
       " 'Kim (Puffin Classics-the Essential Collection)': 3016,\n",
       " \"King Solomon's Mines (Tor Classics)\": 3017,\n",
       " \"L'Appel de la for�?ªt\": 3019,\n",
       " \"L'Orage\": 3022,\n",
       " 'La Citadelle Du Vertige': 3024,\n",
       " 'La Fiesta De Ralph': 3027,\n",
       " 'La Testa Fra Le Nuvole': 3035,\n",
       " 'La casa de los espíritus': 3047,\n",
       " 'La hija del Caníbal': 3051,\n",
       " 'La petite �?©cuy�?¨re a caft�?©': 3055,\n",
       " 'Le Grand Meaulnes (Classiques De Poche)': 3072,\n",
       " \"Le Parfum : Histoire d'un meurtrier\": 3105,\n",
       " 'Le Petit Prince. (Franz�?¶sische Ausgabe). (Lernmaterialien)': 3107,\n",
       " 'Le chateau des carpathes': 3109,\n",
       " 'Les Confessions: Livres I �?\\xa0 IV': 3115,\n",
       " 'Les Particules Elementaires': 3118,\n",
       " 'Les Six Compagnons �?\\xa0 Scotland Yard': 3120,\n",
       " \"Les Tuniques bleues, tome 1 : un chariot dans l'ouest\": 3122,\n",
       " 'Les derniers g�?©ants': 3124,\n",
       " \"Les derniers po�?¨mes d'amour\": 3125,\n",
       " 'Lieber Sport als Mord.': 3126,\n",
       " 'Lightning': 3246,\n",
       " 'Little Altars Everywhere': 3307,\n",
       " 'Live aus Bagdad. Das Tagebuch einer Kriegs-Reporterin.': 3309,\n",
       " 'Los Calusari/the Calusari (Coleccion \\\\\"Expediente X\\\\\"/the X Files Series)': 3310,\n",
       " 'Los Trapos Sucios - Manolito Gafotas': 3314,\n",
       " 'Love Story': 3319,\n",
       " \"Love in the Time of Cholera (Everyman's Library (Cloth))\": 3322,\n",
       " 'L�?©onard, tome 1 : L�?©onard est un g�?©nie': 3324,\n",
       " 'Make Them Cry': 3334,\n",
       " 'Manhattan Hunt Club': 3434,\n",
       " 'Matilda': 3445,\n",
       " 'Maudit Manege': 3451,\n",
       " 'Mit dem K�?¼hlschrank durch Irland.': 3467,\n",
       " 'Moby Dick (Coleccion)': 3468,\n",
       " 'Moby Dick. ( Ab 12 J.).': 3469,\n",
       " 'Mon bel oranger': 3471,\n",
       " 'Moon Handbooks: Hawaii': 3473,\n",
       " 'Move to Strike': 3547,\n",
       " 'Murder at the Margin': 3548,\n",
       " 'My \\\\\"Star Trek\\\\\" Memories': 3551,\n",
       " 'Mycroft Holmes Contra La Hermandad': 3552,\n",
       " 'Nachtschicht.': 3566,\n",
       " 'Nadie Es Perfecto (Narrativa Actual)': 3567,\n",
       " 'Night Sins': 3724,\n",
       " 'Nomadentochter.': 3725,\n",
       " 'Nordermoor': 3739,\n",
       " 'Nur der Tod ist ohne Makel.': 3746,\n",
       " 'O Pioneers! (Bantam Classic)': 3752,\n",
       " 'Oceano Mare': 3777,\n",
       " 'Of Mice and Men. Text and Study Aids. (Lernmaterialien)': 3778,\n",
       " 'One': 3840,\n",
       " \"One Flew over the Cuckoo's Nest (Penguin Classics)\": 3844,\n",
       " 'One Thousand Chestnut Trees': 3845,\n",
       " 'Overnight (Fear Street) : Overnight (Fear Street Series)': 3848,\n",
       " 'PERFUME : PERFUME': 3878,\n",
       " 'Pay Dirt (Mrs. Murphy Mysteries (Paperback))': 3901,\n",
       " \"Percevan, tome 1 : Les Trois Etoiles d'Ingaar\": 3903,\n",
       " 'Piccoli Equivoci Senza Importanza: Piccoli Equivoci Senza Importanza': 3909,\n",
       " 'Politically Correct Bedtime Stories: Modern Tales for Our Life and Times': 4062,\n",
       " 'Por los pelos': 4063,\n",
       " 'Prinz der Kelche.': 4064,\n",
       " 'Q': 4088,\n",
       " 'Quidditch Through the Ages': 4105,\n",
       " 'Rabbit in Ruhe.': 4106,\n",
       " 'Rand.': 4109,\n",
       " 'Random Acts of Kindness': 4112,\n",
       " 'Reif f�?¼r die Insel. England f�?¼r Anf�?¤nger und Fortgeschrittene.': 4115,\n",
       " 'Reise nach Ixtlan. Die Lehre des Don Juan.': 4122,\n",
       " 'Richard Brautigan : A Confederate General from Big Sur, Dreaming of Babylon, and the Hawkline Monster (Three Books in the Manner of Their Original ed)': 4126,\n",
       " 'Rites of Passage': 4128,\n",
       " 'Roan (Blake, Jennifer, Louisiana Gentlemen Series.)': 4140,\n",
       " 'Round about Midnight: A Portrait of Miles Davis': 4143,\n",
       " 'Saemtliche Erzaehlungen': 4147,\n",
       " 'Saving Private Ryan': 4151,\n",
       " 'Schlafes Bruder': 4185,\n",
       " 'See Jane Run': 4228,\n",
       " 'Shadowland': 4238,\n",
       " 'Siddharta Romanzo Versione Di M Mila': 4270,\n",
       " 'Skin and Other Stories (Now in Speak!)': 4278,\n",
       " 'Soul Survivor': 4285,\n",
       " 'Southampton Row (Charlotte &amp': 4299,\n",
       " 'Speaking in Tongues': 4363,\n",
       " 'Storm Surge: A Quin St. James and Mike McCleary Mystery': 4365,\n",
       " 'Stupeur Et Tremblements': 4395,\n",
       " 'Sturm der Liebe.': 4397,\n",
       " 'Surviving Sam': 4400,\n",
       " 'Sushi for Beginners : A Novel (Keyes, Marian)': 4422,\n",
       " 'Tales of the Greek Heroes: Retold from the Ancient Authors (Puffin Classics)': 4428,\n",
       " 'The Amsterdam Connection : Level 4 (Cambridge English Readers)': 4429,\n",
       " \"The Best of Bombeck: At Wit's End, Just Wait Until You Have Children of Your Own, I Lost Everything in the Post-Natal Depression\": 4442,\n",
       " 'The Boy Next Door': 4542,\n",
       " 'The Circle And The Cross 1: Playing Of': 4545,\n",
       " \"The Complete Idiot's Guide to the Microsoft Network\": 4546,\n",
       " 'The Complete Idiots Guide to Getting the Job You Want (W/2 Discs)': 4547,\n",
       " 'The Contest': 4552,\n",
       " 'The Coral Island (Puffin Classics)': 4557,\n",
       " 'The Da Vinci Code': 5369,\n",
       " 'The Dark Half': 5513,\n",
       " 'The Girl Who Loved Tom Gordon : A Novel': 5615,\n",
       " 'The Golden Rule of Schmoozing': 5616,\n",
       " 'The Holiday Present': 5646,\n",
       " 'The Jester': 5719,\n",
       " 'The Joy Luck Club': 6195,\n",
       " 'The Keys to the Street': 6197,\n",
       " 'The King of Torts': 6409,\n",
       " 'The Last Book in the Universe': 6417,\n",
       " 'The Last Time They Met : A Novel': 6601,\n",
       " 'The Law of Love': 6620,\n",
       " 'The Lovely Bones: A Novel': 7784,\n",
       " 'The MouseDriver Chronicles': 7787,\n",
       " 'The Music of Chance': 7806,\n",
       " 'The Name of the Rose': 7841,\n",
       " 'The Notebook': 7945,\n",
       " 'The Number Devil: A Mathematical Adventure': 7947,\n",
       " 'The Picture of Dorian Gray': 7963,\n",
       " 'The Pillars of the Earth': 8172,\n",
       " 'The Power to Harm: Mind, Medicine, and Murder on Trial': 8173,\n",
       " 'The Rebel Angels': 8197,\n",
       " \"The Restaurant at the End of the Universe (Hitchhiker's Trilogy (Paperback))\": 8251,\n",
       " 'The Riddle of Scheherazade: And Other Amazing Puzzles': 8254,\n",
       " 'The Sandy Bottom Orchestra': 8261,\n",
       " 'The Second Summer of the Sisterhood': 8321,\n",
       " \"The Strange Case of Dr. Jekyll and Mr. Hyde and Weir of Hermiston: And, Weir of Hermiston (Oxford World's Classics)\": 8323,\n",
       " 'The Tower at Stony Wood': 8332,\n",
       " 'The Watsons Go to Birmingham - 1963 (Yearling Newbery)': 8348,\n",
       " 'The Wonderful Story of Henry Sugar and Six More': 8360,\n",
       " 'The X-Files: Goblins': 8402,\n",
       " 'The X-Files: Ground Zero': 8445,\n",
       " 'The Year of Sharing (Oxford Bookworms)': 8446,\n",
       " 'Tod im wei�?�?en H�?¤ubchen.': 8447,\n",
       " \"Tom Clancy's Op- Center. Spiegelbild.\": 8450,\n",
       " 'Toxin': 8453,\n",
       " 'Ubu Roi*': 8457,\n",
       " \"Un Amore Dell'altro Mondo\": 8460,\n",
       " 'Un Bon Petit Diable': 8462,\n",
       " \"Un Giorno Dopo L'altro\": 8471,\n",
       " 'Undank ist der V�?¤ter Lohn.': 8476,\n",
       " 'Ungarn.': 8477,\n",
       " 'Uther (Camulod Chronicles)': 8482,\n",
       " 'Vater Himmel, Mutter Erde.': 8484,\n",
       " 'Verraten und verkauft. Roman.': 8486,\n",
       " 'Vieja Nueva York': 8487,\n",
       " 'Waiting for Godot': 8494,\n",
       " 'Waiting to Exhale': 8575,\n",
       " 'Walk Two Moons': 8632,\n",
       " 'Was Mir Wichtig War: Letzte Aufzeichnungen Und Gesprache': 8633,\n",
       " 'Wasted : A Memoir of Anorexia and Bulimia': 8651,\n",
       " \"What's That Pig Outdoors: A Memoir of Deafness\": 8654,\n",
       " 'Whirlwind (The X-Files)': 8705,\n",
       " 'Whispers': 8772,\n",
       " 'Wild Animus': 9993,\n",
       " 'Wilt: Tom Sharpe': 9996,\n",
       " '¡No bajes al sótano! (Escalofríos No. 2)': 9997}"
      ]
     },
     "execution_count": 266,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create mapper from book title to index\n",
    "# book: index\n",
    "book_to_idx = {\n",
    "    book: i for i, book in enumerate(list(dfBook.set_index('BookTitle').loc[df_boo.index].index))\n",
    "}\n",
    "book_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrKKbiRJYb5g"
   },
   "source": [
    "**2.3 Initialize and train two different KNN models (use cosine metric for similarity for both) but with different n_neighbours, 2 and 10. Recommend top 5 books based on your favourite one in both cases (1 points)**<br>\n",
    "NB: You are free to choose a favorite book (any book) based on which you have to recommend 5 books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpqEOCFKAtWy",
    "outputId": "ab4540a2-c4ed-400e-feb3-f8cad16140da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
      "                 metric_params=None, n_jobs=-1, n_neighbors=10, p=2,\n",
      "                 radius=1.0)\n",
      "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
      "                 metric_params=None, n_jobs=-1, n_neighbors=2, p=2, radius=1.0)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# define model: using cosine for similarity \n",
    "model_knn_null = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=2, n_jobs=-1)\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=10, n_jobs=-1)\n",
    "\n",
    "\n",
    "# fit the model\n",
    "print(model_knn.fit(df_boo_sparse))\n",
    "print(model_knn_null.fit(df_boo_sparse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t4_7s1gozZO6",
    "outputId": "4a5a809d-10ca-437d-ce5e-7e4ac0a9e9f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (0.18.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "O7lfuKtV2Dbo"
   },
   "outputs": [],
   "source": [
    "# Import the required libraries:\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "4XtAtZ63eWEb"
   },
   "outputs": [],
   "source": [
    "def fuzzy_matching(mapper, fav_book, verbose=True):\n",
    "    # Get match\n",
    "    match_tuple = []\n",
    "    for title, idx in mapper.items():\n",
    "        ratio = fuzz.ratio(BookTitle.lower(), fav_book.lower())\n",
    "        if ratio >= 500:\n",
    "           match_tuple.append((df_boo['BookTitle'], idx, ratio))\n",
    "  \n",
    "    # Sort\n",
    "    match_tuple = sorted(match_tuple, key = lambda x: x[2])[::-1]\n",
    "    if not match_tuple:\n",
    "        print('Oops! No match is found')\n",
    "        return\n",
    "    if verbose:\n",
    "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
    "    return match_tuple[0][1]\n",
    "\n",
    "def make_recommendation(model_knn, data, mapper, fav_book, n_recommendations):\n",
    "    # data = df_boo\n",
    "    model_knn.fit(data)\n",
    "\n",
    "    # get input book index\n",
    "    print('You have input book:', fav_book)\n",
    "    idx = fuzzy_matching(mapper, fav_book, verbose=True)\n",
    "\n",
    "    # Inference\n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "\n",
    "    # Get list of raw idx of recommendations\n",
    "    raw_recommends = \\\n",
    "        sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    \n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "\n",
    "    # print recommendation:\n",
    "    print('Recommendations for {}:'.format(fav_book))\n",
    "    for i, (idx, dist) in reversed(list(enumerate(raw_recommends))):\n",
    "        #j =i\n",
    "        print('{0}: {1}, with distance of {2}'.format(n_recommendations-i, reverse_mapper[idx], dist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rHFrCq96d30"
   },
   "outputs": [],
   "source": [
    "my_favorite = 'Matilda' # Matilda\n",
    "\n",
    "make_recommendation(\n",
    "    model_knn=model_knn, # trained model (model)\n",
    "    data=df_boo_sparse, # sparse matrix (data)\n",
    "    fav_book=my_favorite, # fav_book\n",
    "    mapper=book_to_idx, # {book: index} (mapper)\n",
    "    n_recommendations=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "id": "7Z-tQZBj38hT"
   },
   "outputs": [],
   "source": [
    "data = df_boo_sparse\n",
    "\n",
    "def fuzzy_matching(mapper, fav_book, verbose=True):\n",
    "    match_tuple = []\n",
    "    for title, idx in mapper.items():\n",
    "        ratio = fuzz.ratio(title.lower(), fav_book.lower())\n",
    "        if ratio >= 60:\n",
    "           match_tuple.append((title, idx, ratio))\n",
    "  \n",
    "    match_tuple = sorted(match_tuple, key = lambda x: x[2])[::-1]\n",
    "    if not match_tuple:\n",
    "        print('Oops! No match is found')\n",
    "        return\n",
    "    if verbose:\n",
    "        print('Found possible matches in our database: {0}\\n'.format([x[0] for x in match_tuple]))\n",
    "    return match_tuple[0][1]\n",
    "\n",
    "def make_recommendation(model_knn_null, data, mapper, fav_book, n_recommendations):\n",
    "    # data = df_boo\n",
    "    model_knn_null.fit(data)\n",
    "\n",
    "    # get input book index\n",
    "    print('You have input book:', fav_book)\n",
    "    idx = fuzzy_matching(mapper, fav_book, verbose=True)\n",
    "\n",
    "    # Inference\n",
    "    print('Recommendation system start to make inference')\n",
    "    print('......\\n')\n",
    "    distances, indices = model_knn_null.kneighbors(data[idx], n_neighbors=n_recommendations+1)\n",
    "\n",
    "    # Get list of raw idx of recommendations\n",
    "    raw_recommends = \\\n",
    "        sorted(list(zip(indices.squeeze().tolist(), distances.squeeze().tolist())), key=lambda x: x[1])[:0:-1]\n",
    "    \n",
    "    # get reverse mapper\n",
    "    reverse_mapper = {v: k for k, v in mapper.items()}\n",
    "\n",
    "    # print recommendation:\n",
    "    print('Recommendations for {}:'.format(fav_book))\n",
    "    for i, (idx, dist) in reversed(list(enumerate(raw_recommends))):\n",
    "        #j =i\n",
    "        print('{0}: {1}, with distance of {2}'.format(n_recommendations-i, reverse_mapper[idx], dist))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5O6AfDal_kFs"
   },
   "outputs": [],
   "source": [
    "my_favorite = 'Shadowland' # The Da Vinci Code\n",
    "\n",
    "make_recommendation(\n",
    "    model_knn_null=model_knn_null, # trained model (model)\n",
    "    data= df_boo_sparse, # sparse matrix (data)\n",
    "    fav_book=my_favorite, # fav_book\n",
    "    mapper=book_to_idx, # {book: index} (mapper)\n",
    "    n_recommendations=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCJz_Do9Yb5q"
   },
   "source": [
    "**2.4 Discuss the results you received from both models. Which one worked better? (0.25 points)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2CdPc75QYb5r"
   },
   "source": [
    "<font color='red'> **Answer: Based on the result, I found the recommendation are quite similar to the choice I have selected. Whether I have selected Matilda-The davnci code- Shadowland, etc. Thanks to the main factors I have here: Model_knn function & mapper. They are factors of the main factors that the recommendations mechanism are absed on.**</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G6T3K3VFYb5s"
   },
   "source": [
    "**2.5 Add a new user (with user “UserID” = 6293) in your data. Using the two trained models in task 2.3 suggest which books should this user read if his ratings are:**\n",
    "\n",
    "French Cuisine for All: 4\n",
    "\n",
    "\n",
    "Harry Potter and the Sorcerer's Stone Movie Poster Book: 5\n",
    "\n",
    "\n",
    "El Perfume: Historia De UN Asesino/Perfume : The Story of a Murderer: 1\n",
    "\n",
    "**(1. 25 points)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "62_Jfn7cNYie"
   },
   "outputs": [],
   "source": [
    "# Edit my dataset a little bit:\n",
    "\n",
    "features = ['UserID', 'BookTitle', 'Book-Rating']\n",
    "\n",
    "# Get each row as a string\n",
    "def combine_features(row):\n",
    "    return row['Book-Rating']+\" \"+row['UserID']+\" \"+row['BookTitle']\n",
    "\n",
    "for feature in features:\n",
    "    dfBook[feature] = dfBook[feature].fillna('')\n",
    "\n",
    "dfBook[\"combined_features\"] = dfBook.apply(combine_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-EJOEy1Yb5t"
   },
   "outputs": [],
   "source": [
    "# In case model_knn case:\n",
    "\n",
    "def get_title_from_index(index):\n",
    "    return df[df.index == index][\"title\"].values[0]\n",
    "\n",
    "def get_index_from_title(title):\n",
    "    return dfBook[dfBook['BookTitle'] == title][\"index\"].values[0]\n",
    "\n",
    "book_user_likes = \"Shadowland\"\n",
    "\n",
    "book_index = get_index_from_title(book_user_likes)\n",
    "similar_books =  list(enumerate(cosine_sim[book_index]))\n",
    "\n",
    "sorted_similar_books = sorted(similar_books,key=lambda x:x[1],reverse=True)[1:]\n",
    "i=0\n",
    "print(\"Top 5 similar movies to \"+book_user_likes+\" are:\\n\")\n",
    "for element in sorted_similar_books:\n",
    "    print(get_title_from_index(element[0]))\n",
    "    i=i+1\n",
    "    if i>=5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMyW4UlbYb5x"
   },
   "source": [
    "# 3. Recommender systems evaluation (1 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EINSDAbXYb5y"
   },
   "source": [
    "We are going to compare different methods of recommender systems by their RMSE score. One useful package that has several recommender algorithms for Python is [Surprise](https://surprise.readthedocs.io/en/stable/getting_started.html). Below we have split the books dataset into training and test and used the KNNBasic algorithm to predict the ratings for the test set using surprise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unS3lDvaTAWa",
    "outputId": "f4b33a52-e4ea-438a-e274-63439e333b8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting surprise\n",
      "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
      "Collecting scikit-surprise\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
      "\u001b[K     |████████████████████████████████| 11.8MB 8.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1617616 sha256=bdba3230a10dd6e75f46174391c6bfcfa2edb8799910469f420e88c531095d2a\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise, surprise\n",
      "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
     ]
    }
   ],
   "source": [
    "pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OoLm-EC1Yb5z",
    "outputId": "96b7938a-b6d2-4422-d10a-4bcf4d6cdf6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 4.2460\n",
      "KNN RMSE 4.245996264575798\n"
     ]
    }
   ],
   "source": [
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import SVD\n",
    "from surprise import NormalPredictor\n",
    "from surprise import KNNBasic\n",
    "\n",
    "# The reader is necessary for surprise to interpret the ratings\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "\n",
    "# This function loads data from a pandas dataframe into surprise dataset structure\n",
    "# The columns should always be ordered like this\n",
    "data = Dataset.load_from_df(dfBook[['UserID', 'BookTitle', 'Book-Rating']], reader)\n",
    "\n",
    "# Split in trainset and testset\n",
    "# No need to define the label y because for surprise the last column is always the rating\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0 )\n",
    "\n",
    "knn = KNNBasic()\n",
    "knn.fit(trainset)\n",
    "predictions = knn.test(testset)\n",
    "print('KNN RMSE', accuracy.rmse(predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdIaAghiYb53"
   },
   "source": [
    "**3.1 After taking a look at surprise documentation and the code above, follow the same steps as with KNN, and predict the ratings in test set using the NormalPredictor which predicts a random rating based on the distribution of the training set. Do the same for SVD which  is a matrix factorization technique. For both of them report RMSE. (1 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VWcalcl4Yb56",
    "outputId": "719b118f-db13-47ea-aead-d4b7528c45f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': (0.009940624237060547, 0.017148733139038086),\n",
       " 'test_mae': array([4.13615993, 4.20063101]),\n",
       " 'test_rmse': array([5.15930774, 5.19299781]),\n",
       " 'test_time': (0.0437009334564209, 0.042124271392822266)}"
      ]
     },
     "execution_count": 319,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO: Normal predictor\n",
    "# First Recall the libraries:\n",
    "\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "\n",
    "# We can now use this dataset as we please, e.g. calling cross_validate\n",
    "cross_validate(NormalPredictor(), data, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hr29lRYSW8Bo",
    "outputId": "4f96ebd0-7495-4a9e-9106-3ba7830e5877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.2389\n",
      "RMSE: 4.2671\n",
      "RMSE: 4.3355\n"
     ]
    }
   ],
   "source": [
    "#TODO: SVD\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_DPXBrvXIwk"
   },
   "source": [
    "### **Conclusion: RMSE for SVD is in range 4.2389 to 4.3355. Unlike the NormalPredictor that generates an array..**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OjJgAOSRYb6A"
   },
   "source": [
    "# 4. Neural Networks (2.5 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5TF1ePBYb6L"
   },
   "source": [
    "**4.1 We are now going to build a recommender system using Neural Networks. Being this dataset is really small in terms of features you might not see great improvements but it is a good starting point to learn. Please build  one of the neural network architechtures as we did in practice session part 3. You can for example choose the one which had the following layers:**\n",
    "- 2 Embedding\n",
    "- 2 Reshape\n",
    "- 1 Concatenation \n",
    "- 1 Dense\n",
    "\n",
    "**Use the Neural Network you built to learn from the train data of part 3 of this homework.  The column UserID should be used as input to your NN for the user embedding layer. For the books embedding layer we will use BookTitle column. Lastly, the ratings will be your target variable. Regarding the evaluation metric for the training phase use RMSE. To make your training fast you can use a batch size of 200 or above. (1.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PbuvaC1eYb6Q",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "from keras import backend\n",
    "\n",
    "from keras.layers import Input, Embedding, Flatten, Dot, Dense,multiply, concatenate, Dropout, Reshape\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "#Method for RMSE calculation\n",
    "def rmse(true_label, pred_label):\n",
    "    return #TODO: RMSE function\n",
    "\n",
    "#TODO: Data preparation\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/RewanEmam/Customer-Segmentation-files/main/Books.csv',\n",
    "                 header=0, sep = ',', usecols=['UserID', 'Book-Rating', 'BookTitle'])\n",
    "\n",
    "#TODO: Model\n",
    "def RecommenderV1(user_id, title, ratings):\n",
    "     user_id = Input(shape=(1,))\n",
    "     u = Embedding(user_id, ratings, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(user_id)\n",
    "     u = Reshape((n_factors,))(u)\n",
    "\n",
    "     #TODO: Embedding user id\n",
    "     title = Input(shape=(50,))\n",
    "      m = Embedding(title,ratings, embeddings_initializer='he_normal',\n",
    "                  embeddings_regularizer=l2(1e-6))(title)\n",
    "      m = Reshape((n_factors,))(m)\n",
    "\n",
    "\n",
    "      x = Dot(axes=1)([u, m])\n",
    "  \n",
    "      model = Model(inputs = (id_em, title_em), outputs = out)\n",
    "      model.compile(optimizer = 'Adam', loss = rmse, metrics = ['accuracy'])\n",
    "\n",
    "#TODO: Train model\n",
    "history = model.fit(x=X_train_array, y=y_train, batch_size=200, epochs=150,\n",
    "                    verbose=1, validation_data=(X_test_array, y_test))\n",
    "    \n",
    "    \n",
    "#TODO: pass data, batch_size=200, epochs=150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HsmPj7Wq1cyS"
   },
   "source": [
    "**4.2 Plot the RMSE values during the training phase, as well as the model loss. Report the best RMSE. Is it better than the RMSE from the models we built in Section 2 and 3 ? (0.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCJFqfDm1-HA"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LVLaC5K11-fN"
   },
   "source": [
    "**4.3 Use your trained model to recommend books for user with ID 6293. (0.5 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHQrNa35Jmjo"
   },
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwpOi51caTUp"
   },
   "source": [
    "## How long did it take you to solve the homework?\n",
    "\n",
    "* Please answer as precisely as you can. It does not affect your points or grade in any way. It is okay, if it took 0.5 hours or 24 hours. The collected information will be used to improve future homeworks.\n",
    "\n",
    "<font color='red'> **Answer: X hours**</font>\n",
    "\n",
    "\n",
    "## What is the level of difficulty for this homework?\n",
    "you can put only number between $0:10$ ($0:$ easy, $10:$ difficult)\n",
    "\n",
    "<font color='red'> **Answer:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nJX9pZJRAtW3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Homework_04.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
